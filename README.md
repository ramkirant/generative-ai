# Generative AI

## Precursors

### What is Artificial Intelligence?

Artificial Intelligence is a broad field of computer science that focuses on creating intelligent systems capable of performing tasks that typically require human intelligence. 

### What are the different types of AI Systems

- Conventional AI Systems

  Conventional AI Systems trains by learning from a set of input data and performs predictions. 
  
- Generative AI Systems

  Generative AI Systems needs tremendous amounts of input data. Based upon the training data, using the neural networks behind the scenes, Generative AI systems would be able to generate new content.
  
### How would machines be able to perform tasks that require human intelligence?

Machines would be able to perform these tasks by leveraging **Machine Learning**

### What is Machine Learning?

Machine learning is a subset of AI that focuses on development of algorithms or models that enable computers to learn and make predictions or decisions without explicit programming. 

### What is needed for a machine to learn?

- Huge sets of Training Data
- High Computational Power
- Optimized and Resilient Training Algorithms.

### What are the different variants of Machine Learning?

- Deep Learning

### What is Deep Learning?

Deep Learning is a subset of Machine Learning that learns using the concept of neurons of a human brain. Deep Learning leverages Neural Networks to process data. Neural Network is a network of multiple machines where the data is passed from one layer of machines to another. Each layer of machines processes the data and sends it to the next layer for further processing. Neural Networks need a lot of computational power which is the reason for a resistance to adopt them during the early days. Recently, this computational power is made easily available. GPUs have become much cheaper and have become more affordable. This made adoption of Neural Networks for various Deep Learning use cases easy.

*Deep Learning is a subset of Machine Learning*

*Machine Learning is a subset of Artificial Intelligence*

## ChatGPT

### What is ChatGPT?

ChatGPT is a large language model (LLM). It is designed with natural language understanding and generation. It can handle a conversational context. It remembers the background of a conversation.

- It is a Generative AI application
- Developed by OpenAI
- Trained on billions of documents
- Based on Generative Pre-Trained Transformer (GPT) architecture, a type of neural network. 
- It offers Web Interface for end-users and API for developers. 

## Generative AI

### Where does Generative AI fits into this Artificial Intelligence Landscape?

Generative AI is a subset of Deep Learning. It uses Deep Learning Neural Networks to learn from the Training Data and generate new content from it. 

Generative Artificial Intelligence (Gen AI) is a type of AI that can create new content, such as audio, images, text, code, videos etc. 

### Key Terminologies of Generative AI

- LLM
- Prompt Engineering
- Embeddings
- Fine Tuning

### Large Language Models (LLMs)

LLMs are powerful artificial intelligence models that are designed for understanding and generating human-like text. 

People usually use the words Generative AI and LLMs interchangeably, but they are not the same. Generative AI generates all types of content ranging from Text, Image, Audio, Video, Code Snippets etc. LLM is a subset of GenerativeAI and is used only to generate text.

The brains behind LLM is a neural network called Transformer. Transformer is very good at understanding human language, words, sentences and context. 

#### Key Points of LLM
- Pre-Trained: LLMs are trained on a huge corpus of data. 
- Size and Scale: LLMs use massive neural networks called transformers, and they contain billions of parameters. Parameters are like variables that are used to train the model. Higher the number of parameters, better is the model, training, understanding and generation. 
- Fine-Tuned: More targeted training for specific tasks. 